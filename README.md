# Data-Science-Projects
Collection of data science projects, ranging between personal and educational and research!

[Iris Species Prediction](https://github.com/ankushbharadwaj/Data-Science-Projects/tree/master/Iris%20Species%20Prediction): Tested the accuracy of different machine learning algorithms in predicting the exact species of *Iris* flower based off *Iris* flower data set collected by Edgar Anderson to study the morphologic variation within closely related species of *Iris* flowers. Upon deciding to use the K-Nearest Neighbors algorithm for its accuracy and simplicity, tested the accuracy of my model on the validation set and quantified the model's accuracy for predicting the species of *Iris* based on sepal and petal measurements to be 90%.

***********************************************************

[Loan Prediction](https://github.com/ankushbharadwaj/Data-Science-Projects/tree/master/Loan%20Prediction): Automated processes of a theoretical home loan company by predicting whether or not an individual's loan would be approved by using classification algorithms. Finally settled on using the Random forest algorithm with the predictor variables as follows: Total Income, Loan Amount, Credit History, Dependents, and Property Area. My model, using a Random Forest algorithm, yielded an accuracy of 82.736% and a cross-validation score of 80.297%. 

***********************************************************

[Wine Quality Prediction](https://github.com/ankushbharadwaj/Data-Science-Projects/tree/master/Wine%20Quality%20Prediction): Utilized principal component analysis (PCA) to reduce the variables in a wine quality data set, from this [link](https://archive.ics.uci.edu/ml/datasets/Wine+Quality). After reducing variables to 6 latent variables decided via the aforementioned PCA, used a Na√Øve Bayes classifier to predict the quality of wine on a test subset of the overall dataset based upon these 6 latent variables. The accuracy I achieved with this model was a relatively low 53.873%. This can be either attributed to the model being inaccurate, or to the fact that wine quality is based arbitrarily on critics' opinions and can't be consistently predicted through objective qualities of the wine. 

***********************************************************

[Boston Home Price Prediction](https://github.com/ankushbharadwaj/Data-Science-Projects/tree/master/Boston%20Home%20Price%20Prediction): Given sample data about 506 homes in Boston and 13 features for each sample, built a linear regression model to predict the price of a house. First, performed regression with only one feature, which in this case was the feature that indicated the number of rooms in a house. The Root Mean Squared Error and R^2 for this regression were 4.9 and .69, respectively. Next, performed a regression using all features, resulting in a Root Mean Squared Error and R^2 of 4.9 and .67, respectively, indicating some benefits of using a regression with just one feature, as this regerssion more accurately fits the data. 

***********************************************************

[BBC Article Classification](https://github.com/ankushbharadwaj/Data-Science-Projects/tree/master/BBC%20Article%20Classification): Downloaded publicly available [BBC news article datasets](http://mlg.ucd.ie/datasets/bbc.html) with the intention of deciding on a supervised learning algorithm that can most accurately categorize articles into either 'sport', 'business', 'tech', 'politics', or 'entertainment' when provided with the text of the article, along with gaining valuable insight into factors that differentiate news articles in these categories. 

First, created a dataset with the following features: 'Filename', 'Content', 'Category' through readtext package in [RStudio](https://github.com/ankushbharadwaj/Data-Science-Projects/blob/master/BBC%20Article%20Classification/dataset_creation.R). 'Filename' is the name of the file that contains the news article being observed in that row, 'Content' is the un-parsed text of the news article, and 'Category' is which news category the article belongs to. 

Next, performed [exploratory data analysis and data cleansing](https://github.com/ankushbharadwaj/Data-Science-Projects/blob/master/BBC%20Article%20Classification/EDA_bbc_article.ipynb) by removing "README.TXT" instances, observing percentage distribution of articles by category, as well as distribution of articles by article length, while making adjustments to dataset to bring distributions closer to a normal distribution. 

Most recent action taken on this project is the [feature engineering](https://github.com/ankushbharadwaj/Data-Science-Projects/blob/master/BBC%20Article%20Classification/bbc-articles-featureengineering.ipynb), where the following parsing of the content was done: delete special characters, lowercase all characters, delete punctuation marks, ignore possessive cases, lemmatize the content, and delete English stopwords. Furthermore, category codes were assinged to each different category of news article type and train/test datasets were formed. Finally, elected to use TF-IDF vector representation for text and set the appropriate parameters for the algorithm. 

***********************************************************

[blink-182 Discography Comparison](https://github.com/ankushbharadwaj/Data-Science-Projects/tree/master/blink-182%20Discography%20Comparison): Used the [Spotify Web API](https://developer.spotify.com/documentation/web-api/) to access music and discography data for American rock band [blink-182](https://en.wikipedia.org/wiki/Blink-182). Afterwards, I cleaned up the dataset and removed some features, and then used Euclidean distance to cluster the individual songs within an album ([dendrogram for *NINE*](https://github.com/ankushbharadwaj/Data-Science-Projects/blob/master/blink-182%20Discography%20Comparison/Rplot%20-%20nine.jpeg) linked as an example), the [individual songs within blink-182's entire discography](https://github.com/ankushbharadwaj/Data-Science-Projects/blob/master/blink-182%20Discography%20Comparison/album%20overall%20song%20comparison.jpeg), and each [overall album to the other albums](https://github.com/ankushbharadwaj/Data-Science-Projects/blob/master/blink-182%20Discography%20Comparison/album%20overall%20comparison%20average.jpeg). The clustering observed in the data can be correlated to changes in the band line-up for each cluster of albums as well as stylistic shifts in the music played by the band within that specific album. Finally, the code used to compare the individual blink-182 songs within its respective album can be found [here](https://github.com/ankushbharadwaj/Data-Science-Projects/blob/master/blink-182%20Discography%20Comparison/blink-182%20album%20individual%20comparison.R), as well as the code for comparing their individual songs to their entire discography and their overall albums to each other [here](https://github.com/ankushbharadwaj/Data-Science-Projects/blob/master/blink-182%20Discography%20Comparison/blink-182%20album%20overall%20comparison.R)

***********************************************************

[Comparing 50 Years of Billboard Hot 100](https://github.com/ankushbharadwaj/Data-Science-Projects/tree/master/Comparing%2050%20Years%20of%20Billboard%20Hot%20100): Downloaded [dataset](https://www.kaggle.com/rakannimer/billboard-lyrics) that contains features from Billboard's Year-End Hot 100 ranging from 1965 to 2015. Features in this original set included are the year a song appeared on the Year-End Hot 100, artist, song name, and lyrics. I then used the [Spotify Web Api](https://developer.spotify.com/documentation/web-api/) and the R library [spotifyr](https://github.com/charlie86/spotifyr) to add audio features (danceability, energy, key, etc.) relating to each artist's song that was in the Year-End Hot 100 dataset. After achieving this dataframe, many values had to be cleaned out, owing to inadequate logical comparisons that resulted in certain artists or songs not being recognized by spotifyr's request for artist audio features. Nevertheless, the Euclidean distance between the songs was calculated, and the songs were grouped together by the averages of the Euclidean distance by the year the song was on the Billboard's Year-End Hot 100. Finally, the averages were clustered together and visualized through a [dendrogram](https://github.com/ankushbharadwaj/Data-Science-Projects/blob/master/Comparing%2050%20Years%20of%20Billboard%20Hot%20100/billboard_dend_1.pdf). Future attempts to improve this project would revolve around 1) attempting to quicken the process of adding audio features (the for-loop I implemented took a few hours to complete), 2) trying to minimize songs lost through inadequate logical comparisons, and 3) implementing more intuitive visualizations to better understand how popular music has changed over 50 years. 

***********************************************************
